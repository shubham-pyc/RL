{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham-pyc/RL/blob/main/Blackjack_Q_Table_Backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "MaqZJU481m6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import gym"
      ],
      "metadata": {
        "id": "-38XmbiP1miM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gym Environment"
      ],
      "metadata": {
        "id": "N2iRbhhv1-7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/gym/blob/master/gym/envs/toy_text/blackjack.py\n",
        "environment = gym.make(\n",
        "    \"Blackjack-v1\",   # environment name\n",
        "    natural=True,     # flag to payout 1.5x on a \"natural\" blackjack win\n",
        "    new_step_api=True # avoids warnings and allows future compatibility\n",
        ")"
      ],
      "metadata": {
        "id": "nkD7AxdZ1fD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ],
      "metadata": {
        "id": "5LQZQ8RT1xVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.quality_table = np.zeros(shape=(32, 11, 2, 2))\n",
        "        self.states_seen = np.zeros(shape=(32, 11, 2, 2))\n",
        "\n",
        "    # self.quality_table[observation] = [quality of stand, quality of hit]\n",
        "    def act(self, observation):\n",
        "        observation = self._clean_state(observation)\n",
        "        return np.random.randint(0, 2)\n",
        "        # return np.argmax(self.quality_table[observation])\n",
        "\n",
        "    def update(self, state, action, reward):\n",
        "        state = self._clean_state(state)\n",
        "        self.states_seen[state + (action,)] += 1\n",
        "        self.quality_table[state + (action,)] += (\n",
        "            (reward - self.quality_table[state + (action,)]) / \n",
        "            self.states_seen[state + (action,)]\n",
        "        )\n",
        "\n",
        "    # cast (10, 5, True) -> np.array([10, 5, 1]) -> (10, 5, 1)\n",
        "    def _clean_state(self, observation):\n",
        "        return tuple(np.array(observation))"
      ],
      "metadata": {
        "id": "WnXCeFYI1w4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Play one simulation with our agent"
      ],
      "metadata": {
        "id": "XIOaH9Sj17wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent()\n",
        "done = False\n",
        "\n",
        "state = environment.reset()\n",
        "states, actions, rewards = [], [], []\n",
        "\n",
        "while not done:\n",
        "    action = agent.act(state)\n",
        "    next_state, reward, done, _, _ = environment.step(action)\n",
        "\n",
        "    states.append(state)\n",
        "    actions.append(action)\n",
        "    rewards.append(reward)\n",
        "\n",
        "    state = next_state\n",
        "\n",
        "for (state, action, reward) in zip(states, actions, rewards):\n",
        "    agent.update(state, action, reward)\n",
        "\n",
        "print(f\"Our hand sum: {state[0]}\")\n",
        "print(f\"Our score: {reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBV4UE9917TA",
        "outputId": "c69c25a2-356c-40c3-e409-3e651770e7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our hand sum: 21\n",
            "Our score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Play multiple simulations with our agent"
      ],
      "metadata": {
        "id": "UV5INbTf3Wti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with variables that should persist between simulations\n",
        "agent = Agent()\n",
        "total_wins = 0\n",
        "total_losses = 0\n",
        "\n",
        "total_reward = 0\n",
        "total_rewards = []\n",
        "\n",
        "# Loop for N simulations\n",
        "for iteration in range(1_000_000):\n",
        "    \n",
        "    state = environment.reset()\n",
        "\n",
        "    done = False\n",
        "    states, actions, rewards = [], [], []\n",
        "\n",
        "    while not done:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _, _ = environment.step(action)\n",
        "\n",
        "        states.append(state)\n",
        "        actions.append(action)\n",
        "        rewards.append(reward)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    for (state, action, reward) in zip(states, actions, rewards):\n",
        "        agent.update(state, action, reward)\n",
        "\n",
        "    # Metric logging\n",
        "    if reward == -1.0:\n",
        "        total_losses += 1\n",
        "    else:\n",
        "        total_wins += 1\n",
        "\n",
        "    total_reward += reward\n",
        "    total_rewards.append(total_reward)"
      ],
      "metadata": {
        "id": "iaKs5TuT2YzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric printing and plotting"
      ],
      "metadata": {
        "id": "yraOE3t64Vmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Wins: {total_wins}\")\n",
        "print(f\"Total Losses: {total_losses}\")\n",
        "\n",
        "print(f\"Win Rate: {100 * total_wins / (total_wins + total_losses):.3f}%\")"
      ],
      "metadata": {
        "id": "9KWpsWeT4NR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([x for x in range(1_000_000)], total_rewards)\n",
        "\n",
        "plt.title(\"Total Reward as we play\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Money\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TcpGT1I-DSil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(\n",
        "    data = np.argmax(agent.quality_table[12:22, 1:, 0], axis=2),\n",
        "    cbar = False,\n",
        "    annot = True,\n",
        "    xticklabels = np.arange(1, 11),\n",
        "    yticklabels = np.arange(12, 22)\n",
        ")\n",
        "plt.title(\"No usable ace | 0 - stand, 1 - hit\")\n",
        "plt.xlabel(\"Dealer's Hand\")\n",
        "plt.ylabel(\"Our Hand\")\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(\n",
        "    data = np.argmax(agent.quality_table[12:22, 1:, 1], axis=2),\n",
        "    annot = True,\n",
        "    cbar = False,\n",
        "    xticklabels = np.arange(1, 11),\n",
        "    yticklabels = np.arange(12, 22)\n",
        ")\n",
        "plt.title(\"Usable ace | 0 - stand, 1 - hit\")\n",
        "plt.xlabel(\"Dealer's Hand\")\n",
        "plt.ylabel(\"Our Hand\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GzRy7_EYFUkq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}